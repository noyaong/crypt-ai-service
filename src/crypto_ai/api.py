"""FastAPI ì„œë²„"""

import asyncio
import json
import os
from contextlib import asynccontextmanager
from typing import Annotated

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field

# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
_service = None


def get_service():
    """ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (lazy initialization)"""
    global _service
    if _service is None:
        from crypto_ai import CryptoAIService

        load_dotenv()
        api_key = os.getenv("CMC_API_KEY")
        if not api_key:
            raise RuntimeError("CMC_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        _service = CryptoAIService(api_key)
    return _service


# ============================================================
# Pydantic Models
# ============================================================


class PriceResponse(BaseModel):
    symbol: str
    name: str
    price_usd: str
    change_1h: str
    change_24h: str
    change_7d: str
    volume_24h: str
    market_cap: str


class ChartAnalysisRequest(BaseModel):
    prices: list[float] = Field(..., min_length=20, description="ê°€ê²© ì‹œê³„ì—´")
    volumes: list[float] = Field(..., min_length=20, description="ê±°ë˜ëŸ‰ ì‹œê³„ì—´")


class ChartAnalysisResponse(BaseModel):
    trend: str
    confidence: float
    probabilities: dict[str, float]
    indicators: dict[str, float]


class HealthResponse(BaseModel):
    status: str
    device: str
    pytorch_version: str


class PredictionResponse(BaseModel):
    symbol: str
    model: str
    prediction: str
    confidence: float
    probabilities: dict[str, float]
    volatility: float | None = None
    volume_change: float | None = None
    indicators: dict[str, float]
    market_sentiment: dict[str, float]  # Fear & Greed, BTC Dominance
    current_price: float
    price_change_24h: float


class AIInsightResponse(BaseModel):
    symbol: str
    predictions: dict  # interval -> prediction details
    sentiment: dict | None = None  # ì„¼í‹°ë©˜íŠ¸ ë°ì´í„°
    insight: str
    available_timeframes: list[str]


# ============================================================
# Lifespan
# ============================================================


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ì‹œì‘/ì¢…ë£Œ ê´€ë¦¬"""
    print("ğŸš€ Crypto AI API ì„œë²„ ì‹œì‘")
    yield
    print("ğŸ‘‹ ì„œë²„ ì¢…ë£Œ")


# ============================================================
# App
# ============================================================

app = FastAPI(
    title="Crypto AI Analysis API",
    description="MacBook MPS + PyTorch ê¸°ë°˜ ì•”í˜¸í™”í ë¶„ì„ ì„œë¹„ìŠ¤",
    version="0.1.0",
    lifespan=lifespan,
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================================
# Endpoints
# ============================================================


@app.get("/health", response_model=HealthResponse, tags=["System"])
async def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    import torch

    from crypto_ai.analyzer import get_device

    device = get_device()
    return HealthResponse(
        status="healthy",
        device=str(device),
        pytorch_version=torch.__version__,
    )


@app.get("/price/{symbol}", response_model=PriceResponse, tags=["Price"])
async def get_price(symbol: str):
    """íŠ¹ì • ì½”ì¸ ì‹œì„¸ ì¡°íšŒ"""
    service = get_service()
    result = service.get_price(symbol)

    if "error" in result:
        raise HTTPException(status_code=404, detail=result["error"])

    return PriceResponse(**result)


@app.get("/prices", tags=["Price"])
async def get_multiple_prices(
    symbols: Annotated[str, Query(description="ì‰¼í‘œ êµ¬ë¶„ ì‹¬ë³¼ (ì˜ˆ: BTC,ETH,AVAX)")]
):
    """ì—¬ëŸ¬ ì½”ì¸ ì‹œì„¸ ë™ì‹œ ì¡°íšŒ"""
    service = get_service()
    symbol_list = [s.strip().upper() for s in symbols.split(",")]

    results = []
    for symbol in symbol_list:
        result = service.get_price(symbol)
        results.append(result)

    return {"quotes": results}


@app.post("/analyze/chart", response_model=ChartAnalysisResponse, tags=["Analysis"])
async def analyze_chart(request: ChartAnalysisRequest):
    """ì°¨íŠ¸ ê¸°ìˆ ì  ë¶„ì„"""
    if len(request.prices) != len(request.volumes):
        raise HTTPException(400, "pricesì™€ volumes ê¸¸ì´ê°€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.")

    service = get_service()
    result = service.analyze_chart(request.prices, request.volumes)

    return ChartAnalysisResponse(
        trend=result["trend"].value,
        confidence=result["confidence"],
        probabilities=result["probabilities"],
        indicators=result["indicators"],
    )


@app.get("/insights/market", tags=["Insights"])
async def get_market_insights(
    limit: Annotated[int, Query(ge=10, le=200)] = 50,
):
    """ì „ì²´ ì‹œì¥ ì¸ì‚¬ì´íŠ¸"""
    service = get_service()
    return service.get_market_insights(limit=limit)


@app.get("/insights/{symbol}", tags=["Insights"])
async def get_coin_insights(symbol: str):
    """íŠ¹ì • ì½”ì¸ ì¸ì‚¬ì´íŠ¸"""
    service = get_service()
    insights = service.get_coin_insights(symbol)

    return {"symbol": symbol.upper(), "insights": insights}


@app.get("/insights/ai/{symbol}", response_model=AIInsightResponse, tags=["AI Insights"])
async def get_ai_insight(symbol: str):
    """
    LLM ê¸°ë°˜ ë©€í‹° íƒ€ì„í”„ë ˆì„ AI ì¸ì‚¬ì´íŠ¸

    - **symbol**: ì½”ì¸ ì‹¬ë³¼ (ì˜ˆ: BTC, AVAX)

    ëª¨ë“  í•™ìŠµëœ íƒ€ì„í”„ë ˆì„(1h, 4h, 1d)ì˜ ì˜ˆì¸¡ì„ ìˆ˜ì§‘í•˜ê³ ,
    GPT-4o-minië¥¼ í†µí•´ ì¢…í•©ì ì¸ íˆ¬ì ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Returns:
    - íƒ€ì„í”„ë ˆì„ë³„ ì˜ˆì¸¡ ê²°ê³¼
    - LLM ìƒì„± ì¢…í•© ì¸ì‚¬ì´íŠ¸
    """
    from crypto_ai.llm_insight import generate_ai_insight

    try:
        result = generate_ai_insight(symbol.upper())
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

    if not result["predictions"]:
        raise HTTPException(
            status_code=404,
            detail=f"{symbol.upper()} í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”."
        )

    return AIInsightResponse(**result)


@app.get("/insights/ai/{symbol}/stream", tags=["AI Insights"])
async def get_ai_insight_stream(symbol: str):
    """
    LLM ê¸°ë°˜ ë©€í‹° íƒ€ì„í”„ë ˆì„ AI ì¸ì‚¬ì´íŠ¸ (SSE ìŠ¤íŠ¸ë¦¬ë°)

    - **symbol**: ì½”ì¸ ì‹¬ë³¼ (ì˜ˆ: BTC, AVAX)

    Server-Sent Events (SSE)ë¥¼ í†µí•´ ë¶„ì„ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.

    Progress Events:
    - `progress`: ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
      - `step`: í˜„ì¬ ë‹¨ê³„ (init, load_model, fetch_data, predict, collect_sentiment, generate_insight, complete)
      - `status`: í•œê¸€ ìƒíƒœ ë©”ì‹œì§€
      - `progress`: 0.0 ~ 1.0 ì§„í–‰ë¥ 
      - `details`: ì¶”ê°€ ì •ë³´

    - `result`: ìµœì¢… ê²°ê³¼ (AIInsightResponse í˜•ì‹)

    - `error`: ì˜¤ë¥˜ ë°œìƒ ì‹œ

    Example (JavaScript):
    ```javascript
    const eventSource = new EventSource('/insights/ai/BTC/stream');
    eventSource.onmessage = (event) => {
        const data = JSON.parse(event.data);
        if (data.type === 'progress') {
            console.log(`${data.status} (${Math.round(data.progress * 100)}%)`);
        } else if (data.type === 'result') {
            console.log('Result:', data.data);
            eventSource.close();
        }
    };
    ```
    """
    from crypto_ai.llm_insight import generate_ai_insight, ProgressSteps

    async def event_generator():
        progress_events = []

        def progress_callback(step: str, status: str, progress: float, details: dict | None):
            """ì§„í–‰ ìƒí™© ì½œë°± - ì´ë²¤íŠ¸ íì— ì¶”ê°€"""
            progress_events.append({
                "type": "progress",
                "step": step,
                "status": status,
                "progress": progress,
                "details": details or {},
            })

        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        import concurrent.futures

        def run_insight():
            return generate_ai_insight(
                symbol.upper(),
                progress_callback=progress_callback,
            )

        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(run_insight)

            # ì§„í–‰ ìƒí™© ì´ë²¤íŠ¸ ì „ì†¡
            last_sent = 0
            while not future.done():
                await asyncio.sleep(0.1)

                # ìƒˆ ì´ë²¤íŠ¸ ì „ì†¡
                while last_sent < len(progress_events):
                    event = progress_events[last_sent]
                    yield f"data: {json.dumps(event, ensure_ascii=False)}\n\n"
                    last_sent += 1

            # ë‚¨ì€ ì´ë²¤íŠ¸ ì „ì†¡
            while last_sent < len(progress_events):
                event = progress_events[last_sent]
                yield f"data: {json.dumps(event, ensure_ascii=False)}\n\n"
                last_sent += 1

            # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            try:
                result = future.result()
                if not result["predictions"]:
                    yield f"data: {json.dumps({'type': 'error', 'message': f'{symbol.upper()} í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.'}, ensure_ascii=False)}\n\n"
                else:
                    yield f"data: {json.dumps({'type': 'result', 'data': result}, ensure_ascii=False)}\n\n"
            except Exception as e:
                yield f"data: {json.dumps({'type': 'error', 'message': str(e)}, ensure_ascii=False)}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # nginx ë²„í¼ë§ ë¹„í™œì„±í™”
        },
    )


@app.get("/predict/{symbol}", response_model=PredictionResponse, tags=["AI Prediction"])
async def predict_price(
    symbol: str,
    model: Annotated[str, Query(description="ëª¨ë¸ íƒ€ì…")] = "transformer",
    interval: Annotated[str, Query(description="íƒ€ì„í”„ë ˆì„ (1h, 4h, 1d)")] = "1h",
):
    """
    AI ëª¨ë¸ë¡œ ê°€ê²© ë°©í–¥ ì˜ˆì¸¡

    - **symbol**: ì½”ì¸ ì‹¬ë³¼ (ì˜ˆ: BTC, ETH)
    - **model**: ëª¨ë¸ íƒ€ì… (transformer ë˜ëŠ” lstm)
    - **interval**: íƒ€ì„í”„ë ˆì„ (1h: 1ì‹œê°„ë´‰, 4h: 4ì‹œê°„ë´‰, 1d: ì¼ë´‰)

    Returns:
    - ê°€ê²© ë°©í–¥ ì˜ˆì¸¡ (ìƒìŠ¹/í•˜ë½/íš¡ë³´)
    - í™•ë¥  ë¶„í¬
    - ë³€ë™ì„±, ê±°ë˜ëŸ‰ ì˜ˆì¸¡ (transformer + multi-task)
    - í˜„ì¬ ê¸°ìˆ ì  ì§€í‘œ
    """
    from pathlib import Path

    import torch

    from crypto_ai.preprocessing import DataPipeline, DataConfig, FEATURE_COLUMNS, INPUT_SIZE
    from crypto_ai.analyzer import get_device

    symbol = symbol.upper()

    # interval ìœ íš¨ì„± ê²€ì‚¬
    if interval not in ["1h", "4h", "1d"]:
        raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” interval: {interval}. 1h, 4h, 1d ì¤‘ ì„ íƒí•˜ì„¸ìš”.")

    # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (ì½”ì¸ë³„/íƒ€ì„í”„ë ˆì„ë³„ ë””ë ‰í† ë¦¬)
    if model == "transformer":
        checkpoint_path = Path("checkpoints/transformer") / symbol / interval / "best.pt"
    else:
        checkpoint_path = Path("checkpoints/lstm") / symbol / interval / "best.pt"

    if not checkpoint_path.exists():
        raise HTTPException(
            status_code=404,
            detail=f"{symbol} ({interval}) ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”: scripts/train_transformer.py --symbol {symbol} --interval {interval}"
        )

    device = get_device()

    # ë°ì´í„° ìˆ˜ì§‘ (intervalë³„ ì ì ˆí•œ ì„¤ì •)
    days_map = {"1h": 7, "4h": 30, "1d": 90}
    seq_len_map = {"1h": 60, "4h": 60, "1d": 30}
    days = days_map.get(interval, 7)
    seq_len = seq_len_map.get(interval, 60)
    config = DataConfig(symbol=symbol.upper(), interval=interval, days=days, sequence_length=seq_len)
    pipeline = DataPipeline(config)

    try:
        df = pipeline.fetch_data()
        df = pipeline.compute_features(df)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")

    # íŠ¹ì„± ì¤€ë¹„ (13ê°œ íŠ¹ì„±)
    features = pipeline.normalize_features(df, FEATURE_COLUMNS, fit=True)

    seq_len = config.sequence_length
    if len(features) < seq_len:
        raise HTTPException(status_code=400, detail=f"ë°ì´í„° ë¶€ì¡±: {len(features)}/{seq_len}")

    x = torch.tensor(features[-seq_len:], dtype=torch.float32).unsqueeze(0).to(device)

    # ì˜ˆì¸¡
    direction_names = ["í•˜ë½", "íš¡ë³´", "ìƒìŠ¹"]
    volatility_val = None
    volume_val = None

    if model == "transformer":
        from crypto_ai.transformer import CryptoTransformer

        checkpoint = torch.load(checkpoint_path, map_location=device)
        multi_task = checkpoint.get("multi_task", False)

        transformer = CryptoTransformer(
            input_size=INPUT_SIZE, d_model=64, num_heads=4, num_layers=3, multi_task=multi_task
        )
        transformer.load_state_dict(checkpoint["model_state_dict"])
        transformer = transformer.to(device)
        transformer.eval()

        with torch.no_grad():
            outputs = transformer(x)
            probs = torch.softmax(outputs["direction"], dim=-1).cpu().numpy()[0]

            if multi_task:
                volatility_val = float(outputs["volatility"].cpu().numpy()[0][0])
                volume_val = float(outputs["volume"].cpu().numpy()[0][0])
    else:
        from crypto_ai.analyzer import ChartAnalyzer

        checkpoint = torch.load(checkpoint_path, map_location=device)
        lstm = ChartAnalyzer(input_size=INPUT_SIZE, hidden_size=64, num_layers=2)
        lstm.load_state_dict(checkpoint["model_state_dict"])
        lstm = lstm.to(device)
        lstm.eval()

        with torch.no_grad():
            probs = lstm(x).cpu().numpy()[0]

    direction_idx = int(probs.argmax())
    latest = df.iloc[-1]

    # 24ì‹œê°„ ì „ ëŒ€ë¹„ ë³€ë™ë¥  ê³„ì‚°
    if len(df) >= 24:
        price_24h_ago = df.iloc[-24]['close']
        change_24h = (latest['close'] - price_24h_ago) / price_24h_ago * 100
    else:
        change_24h = latest['returns'] * 100

    return PredictionResponse(
        symbol=symbol,
        model=model,
        prediction=direction_names[direction_idx],
        confidence=float(probs[direction_idx]),
        probabilities={
            "í•˜ë½": float(probs[0]),
            "íš¡ë³´": float(probs[1]),
            "ìƒìŠ¹": float(probs[2]),
        },
        volatility=volatility_val,
        volume_change=volume_val,
        indicators={
            "rsi": float(latest["rsi"]),
            "macd": float(latest["macd"]),
            "bb_position": float(latest["bb_position"]),
        },
        market_sentiment={
            "fear_greed": float(latest["fear_greed"]),
            "btc_dominance": float(latest["btc_dominance"]),
        },
        current_price=float(latest["close"]),
        price_change_24h=float(change_24h),
    )
